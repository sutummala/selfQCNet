{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sutummala/selfQCNet/blob/main/QC_semisupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7mKdSrogTuq"
      },
      "source": [
        "## Load the drive and required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng-GhXnNUWmi",
        "outputId": "550f2efe-b910-4346-93b0-b1a0b6bdcc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V46Ia_BXUa4j"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv3D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling3D\n",
        "from tensorflow.keras.layers import Conv3DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling3D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import UpSampling3D\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_curve, roc_auc_score,accuracy_score\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, matthews_corrcoef, balanced_accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization"
      ],
      "metadata": {
        "id": "mMu12hpMdbcV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgS9iUB0YPFo"
      },
      "outputs": [],
      "source": [
        "# normalizing the input to have values between zero and one to make them suitable for further analysis\n",
        "def normalize(input):\n",
        "  norm_input = []\n",
        "  print(f'shape of input is {np.shape(input[0])}')\n",
        "  for i in range(np.shape(input)[0]):\n",
        "    norm_in = (input[i]-np.min(input[i]))/(np.max(input[i])-np.min(input[i]))\n",
        "    norm_input.append(norm_in)\n",
        "  return np.array(norm_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cropping"
      ],
      "metadata": {
        "id": "bX1-uzBFdfMM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQaY18DfsGol"
      },
      "outputs": [],
      "source": [
        "def crop_input(input, d_s_factor):\n",
        "  \n",
        "  if d_s_factor == 2:\n",
        "    input = input[:, 6:86, 6:102, 6:86]\n",
        "  elif d_s_factor == 4:\n",
        "    input = input[:, 3:43, 4:52, 3:43]\n",
        "\n",
        "  return input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the required correctly aligned and artifically misaligned images"
      ],
      "metadata": {
        "id": "a6XAbanSe0kK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jujCyJkdVIua",
        "outputId": "a951276f-d560-4891-d609-c7a1ffd5414b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(215, 91, 109, 91)\n",
            "values before normalization -26.19167 830.7939\n",
            "shape of input is (80, 96, 80, 1)\n",
            "(215, 80, 96, 80, 1)\n",
            "values after normalization 0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "t1_align = np.load('/content/drive/MyDrive/UnsupervisedQC/T1-mni-dsf2.npy')\n",
        "t1_align = np.float32(t1_align)\n",
        "print(t1_align.shape)\n",
        "t1_align = crop_input(t1_align, 2)\n",
        "t1_align = np.expand_dims(t1_align, axis = -1)\n",
        "\n",
        "print('values before normalization', np.min(t1_align[0]), np.max(t1_align[0]))\n",
        "t1_align_norm = normalize(t1_align)\n",
        "print(t1_align_norm.shape)\n",
        "print('values after normalization', np.min(t1_align_norm[0]), np.max(t1_align_norm[0]))\n",
        "del t1_align"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXaC72ai8ZWi",
        "outputId": "5048b254-dfc0-41b1-e728-5505b4f87327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "values before normalization -306.92776 3532.389\n",
            "shape of input is (80, 96, 80, 1)\n",
            "(250, 80, 96, 80, 1)\n",
            "values after normalization 0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "t1_align_f = np.load('/content/drive/MyDrive/UnsupervisedQC/T1-mni-HCP-am-250threshold.npy')\n",
        "t1_align_f = np.float32(t1_align_f)\n",
        "t1_align_f = crop_input(t1_align_f, 2)\n",
        "t1_align_f = np.expand_dims(t1_align_f, axis = -1)\n",
        "\n",
        "print('values before normalization', np.min(t1_align_f[0]), np.max(t1_align_f[0]))\n",
        "t1_align_f_norm = normalize(t1_align_f)\n",
        "print(t1_align_f_norm.shape)\n",
        "print('values after normalization', np.min(t1_align_f_norm[0]), np.max(t1_align_f_norm[0]))\n",
        "del t1_align_f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF2pj_qWJwSA"
      },
      "source": [
        "## Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEgRPAc1aSlm"
      },
      "outputs": [],
      "source": [
        "activation = tf.keras.activations.relu\n",
        "kernal_initializer = tf.keras.initializers.glorot_normal\n",
        "loss = tf.keras.losses.MeanSquaredError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB8XEU_sLTBB"
      },
      "outputs": [],
      "source": [
        "def create_model_single_conv_noupsamp(input_shape):\n",
        "  input_layer = Input(shape=input_shape, dtype=\"float32\", name=\"INPUT\")\n",
        "\n",
        "  x = Conv3D(32, (3, 3, 3), strides=(1, 1, 1), padding=\"same\", kernel_initializer=kernal_initializer)(input_layer)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activation)(x)\n",
        "  x = MaxPooling3D(strides=2)(x)\n",
        "\n",
        "  x = Conv3D(64, (3, 3, 3), strides=(1, 1, 1), padding=\"same\", kernel_initializer=kernal_initializer)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activation)(x)\n",
        "  x = MaxPooling3D(strides=2)(x)\n",
        "\n",
        "  x = Conv3D(128, (3, 3, 3), strides=(1, 1, 1), padding=\"same\", kernel_initializer=kernal_initializer)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activation)(x)\n",
        "  x = MaxPooling3D(strides=2)(x)\n",
        "\n",
        "  volumeSize = K.int_shape(x)\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  x = Dense(256, activation=activation, kernel_initializer=tf.keras.initializers.glorot_normal, activity_regularizer=regularizers.l2(1e-05))(x)\n",
        "\n",
        "  x = Dense(128, activation=activation, kernel_initializer=tf.keras.initializers.glorot_normal,  activity_regularizer=regularizers.l2(1e-05), name=\"CODE\")(x)\n",
        "\n",
        "  x = Dense(256, activation=activation, kernel_initializer=tf.keras.initializers.glorot_normal, activity_regularizer=regularizers.l2(1e-05))(x)\n",
        "\n",
        "  x = Dense(np.prod(volumeSize[1:]), kernel_initializer=tf.keras.initializers.glorot_normal)(x)\n",
        "\n",
        "  x = Reshape((volumeSize[1], volumeSize[2], volumeSize[3], volumeSize[4]))(x)\n",
        "  \n",
        "  x = UpSampling3D(size = (2, 2, 2))(x)\n",
        "  x = Conv3D(128, (3, 3, 3), strides=(1, 1, 1), padding=\"same\", kernel_initializer=kernal_initializer)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activation)(x)\n",
        "  \n",
        "  x = UpSampling3D(size = (2, 2, 2))(x)\n",
        "  x = Conv3D(64, (3, 3, 3), strides=(1, 1, 1), padding=\"same\", kernel_initializer=kernal_initializer)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activation)(x)\n",
        "  \n",
        "  x = UpSampling3D(size = (2, 2, 2))(x)\n",
        "  x = Conv3D(32, (3, 3, 3), strides=(1, 1, 1), padding=\"same\", kernel_initializer=kernal_initializer)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activation)(x)\n",
        "  \n",
        "\n",
        "  x = Conv3D(1, (3, 3, 3), strides=(1, 1, 1),  padding=\"same\", kernel_initializer=kernal_initializer, name = \"OUTPUT\")(x)\n",
        "  x = Activation(tf.keras.activations.sigmoid)(x)\n",
        "\n",
        "  autoencoder = Model(input_layer, x)\n",
        "  autoencoder.summary()\n",
        "\n",
        "  print(\"Model created successfully\")\n",
        "  return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me4QPS68aled",
        "outputId": "56608219-2dad-42ca-ee8f-ab63327ea179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " INPUT (InputLayer)          [(None, 80, 96, 80, 1)]   0         \n",
            "                                                                 \n",
            " conv3d (Conv3D)             (None, 80, 96, 80, 32)    896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 80, 96, 80, 32)   128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 80, 96, 80, 32)    0         \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 40, 48, 40, 32)   0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 40, 48, 40, 64)    55360     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 40, 48, 40, 64)   256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 40, 48, 40, 64)    0         \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 20, 24, 20, 64)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 20, 24, 20, 128)   221312    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 20, 24, 20, 128)  512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 20, 24, 20, 128)   0         \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 10, 12, 10, 128)  0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 153600)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               39321856  \n",
            "                                                                 \n",
            " CODE (Dense)                (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 153600)            39475200  \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 10, 12, 10, 128)   0         \n",
            "                                                                 \n",
            " up_sampling3d (UpSampling3D  (None, 20, 24, 20, 128)  0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 20, 24, 20, 128)   442496    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 20, 24, 20, 128)  512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 20, 24, 20, 128)   0         \n",
            "                                                                 \n",
            " up_sampling3d_1 (UpSampling  (None, 40, 48, 40, 128)  0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 40, 48, 40, 64)    221248    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 40, 48, 40, 64)   256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 40, 48, 40, 64)    0         \n",
            "                                                                 \n",
            " up_sampling3d_2 (UpSampling  (None, 80, 96, 80, 64)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 80, 96, 80, 32)    55328     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 80, 96, 80, 32)   128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 80, 96, 80, 32)    0         \n",
            "                                                                 \n",
            " OUTPUT (Conv3D)             (None, 80, 96, 80, 1)     865       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 80, 96, 80, 1)     0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,862,273\n",
            "Trainable params: 79,861,377\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Model created successfully\n"
          ]
        }
      ],
      "source": [
        "input_shape = (t1_align_norm.shape[1], t1_align_norm.shape[2], t1_align_norm.shape[3], 1)\n",
        "autoencoder = create_model_single_conv_noupsamp(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKQCsVqVSEZI"
      },
      "source": [
        "## Compilation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wSvGP1XcMMr"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer = tf.keras.optimizers.legacy.Adam(learning_rate = 0.005), loss = tf.keras.losses.MeanSquaredError())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBdv7HnGdA4I"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(t1_align_norm[:300], t1_align_norm[:300], validation_split = 0.1, batch_size = 8, epochs = 20, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE5eL2fjjXQv"
      },
      "source": [
        "## save and load the weights of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U608xaC5x4M"
      },
      "outputs": [],
      "source": [
        "prefix = \"/content/drive/MyDrive/Weights/\"\n",
        "path = prefix  + \"hcp_weights/\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVkq7sAEjE7g"
      },
      "outputs": [],
      "source": [
        "os.mkdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcUJOXQM7-Sa"
      },
      "outputs": [],
      "source": [
        "autoencoder.save_weights(path+\"HCP_300_T2mni_upsamp_L2_bias\", save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvSBUQAv4le2",
        "outputId": "115b038a-72a5-4346-a9f1-b50b0b39025b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fbf9c0a1a00>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "autoencoder.load_weights(path+\"HCP_300_mni_upsamp_L2SR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Threshold calculation & Performance evaluation."
      ],
      "metadata": {
        "id": "cmaDK9g-xpLl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIn2rimlAYyq",
        "outputId": "6254bac3-e8d3-469e-a41e-0feb97505085"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300, 80, 96, 80, 1)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1_align_norm_sel = t1_align_norm[300:350]\n",
        "t1_align_f_sel = t1_align_f_norm\n",
        "t1_align_norm_sel = np.append(t1_align_norm_sel, t1_align_f_sel, axis = 0 )\n",
        "t1_align_norm_sel.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xke6KG46uUt6"
      },
      "outputs": [],
      "source": [
        "testing_labels = np.append(np.zeros(50), np.ones(len(t1_align_f_sel)))\n",
        "print(testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qep5KrRLLc82"
      },
      "outputs": [],
      "source": [
        "losses_train = [] \n",
        "p = tf.keras.losses.MeanSquaredError()\n",
        "for i in range(np.shape(t1_align_norm_sel)[0]):\n",
        "  predicted_train = autoencoder.predict(t1_align_norm_sel[i:i+1])\n",
        "  losses_train.append(p(predicted_train, t1_align_norm_sel[i:i+1]).numpy())\n",
        "print(losses_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYVgQjHytNTf"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "\n",
        "labels = testing_labels\n",
        "mses = losses_train\n",
        "\n",
        "y_true = labels\n",
        "y_score = mses\n",
        "\n",
        "# Compute fpr, tpr, thresholds and roc auc\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(\"AUC: \", roc_auc)\n",
        "\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(\"ROC on Validation dataset \")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "diff = np.abs(np.array(fpr) - np.array(tpr))\n",
        "max_diff = np.max(diff)\n",
        "index_of_max_diff = np.argmax(diff)\n",
        "threshold_at_max_diff =  thresholds[index_of_max_diff]\n",
        "print(\"threshold_at_max_diff = \", threshold_at_max_diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlEYWHJvvK3e",
        "outputId": "20d65169-96e6-40f3-f2c4-13756f2cc754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confusion_matrix \n",
            " [[ 49   1]\n",
            " [  3 247]]\n",
            "accuracy in identifying the correct alignments: 98.66666666666667 percent\n"
          ]
        }
      ],
      "source": [
        "wrong_predicts = 0\n",
        "labels = []\n",
        "for loss in losses_train:\n",
        "  if loss >= threshold_at_max_diff:\n",
        "    labels = labels + [1]\n",
        "  else:\n",
        "    labels = labels + [0]\n",
        "accuracy = accuracy_score(testing_labels, labels)\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(testing_labels, labels)\n",
        "TN = confusion_matrix[0][0]\n",
        "FP = confusion_matrix[0][1]\n",
        "FN = confusion_matrix[1][0]\n",
        "TP = confusion_matrix[1][1]\n",
        "print(\"confusion_matrix \\n\", confusion_matrix)\n",
        "print(f'accuracy in identifying the correct alignments: {accuracy*100} percent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnrQMo3LLIkH",
        "outputId": "43a1bce5-e150-4f49-e988-ce488b5b756e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 80, 96, 80, 1)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1_align_norm_sel_t = t1_align_norm[350:]\n",
        "t1_align_norm_sel_t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvEbHIklhEt0",
        "outputId": "0c4a0441-1793-455d-e89a-5c16846b930d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.005913236, 0.0070741354, 0.0053468775, 0.0069335033, 0.008324049, 0.0072536324, 0.0060985335, 0.0058533973, 0.0060419724, 0.009181609, 0.0059048464, 0.008701561, 0.010277496, 0.0057144365, 0.005488973, 0.0058647995, 0.0066005858, 0.006037756, 0.005551012, 0.007051306, 0.0061268588, 0.0076903454, 0.008107291, 0.007201929, 0.013812301, 0.006254665, 0.010309189, 0.0076360805, 0.0051533054, 0.0080378195, 0.006754847, 0.0103642, 0.0060882946, 0.007630795, 0.008825901, 0.008392449, 0.0076888036, 0.0067507965, 0.006702007, 0.006328167, 0.008092552, 0.0059834123, 0.004798258, 0.005756157, 0.0054275487, 0.0070553273, 0.0060853134, 0.005892134, 0.005680378, 0.0077593126]\n"
          ]
        }
      ],
      "source": [
        "losses_test = [] \n",
        "for i in range(np.shape(t1_align_norm_sel_t)[0]):\n",
        "  predicted_test = autoencoder.predict(t1_align_norm_sel_t[i:i+1])\n",
        "  losses_test.append(p(predicted_test, t1_align_norm_sel_t[i:i+1]).numpy())\n",
        "print(losses_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGVAUNPVZDzU"
      },
      "outputs": [],
      "source": [
        "testing_labels_t = np.zeros(len(t1_align_norm_sel_t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QJzoj-Hg0SM",
        "outputId": "1dddcad0-9f5d-4373-d71c-ecfeabdc89cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "confusion_matrix \n",
            " [[49  1]\n",
            " [ 0  0]]\n",
            "accuracy in identifying the correct alignments: 98.0 percent\n"
          ]
        }
      ],
      "source": [
        "wrong_predicts = 0\n",
        "labels = []\n",
        "for loss in losses_test:\n",
        "  if loss >= threshold_at_max_diff:\n",
        "    labels = labels + [1]\n",
        "  else:\n",
        "    labels = labels + [0]\n",
        "accuracy = accuracy_score(testing_labels_t, labels)\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(testing_labels_t, labels)\n",
        "print(\"confusion_matrix \\n\", confusion_matrix)\n",
        "print(f'accuracy in identifying the correct alignments: {accuracy*100} percent')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For new test datasets"
      ],
      "metadata": {
        "id": "_T88Rngx00Vt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz6YPye3MT8c",
        "outputId": "0a1a44ea-ce53-42a1-a57a-defbf3d87a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "values before normalization -608.0 12581.0\n",
            "shape of input is (80, 96, 80, 1)\n",
            "(320, 80, 96, 80, 1)\n",
            "values after normalization 0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "  abide_mni = np.load('/content/drive/MyDrive/UnsupervisedQC/T1-mni-dsf2-IOP.npy')\n",
        "  t1_mni_a = np.float32(abide_mni)\n",
        "  t1_mni_a = crop_input(t1_mni_a, 2)\n",
        "  t1_mni_a = np.expand_dims(t1_mni_a, axis = -1)\n",
        "\n",
        "  print('values before normalization', np.min(t1_mni_a[0]), np.max(t1_mni_a[0]))\n",
        "  t1_mni_a_norm = normalize(t1_mni_a)\n",
        "  print(t1_mni_a_norm.shape)\n",
        "  print('values after normalization', np.min(t1_mni_a_norm[0]), np.max(t1_mni_a_norm[0]))\n",
        "  del abide_mni, t1_mni_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fjw1qyxTzft"
      },
      "outputs": [],
      "source": [
        "t1_mni_a_f_norm = np.load('/content/drive/MyDrive/UnsupervisedQC/T2-mni-HCP-am-2000-fullprocessed.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZOJvS0u-ScW"
      },
      "outputs": [],
      "source": [
        "testing_labels = np.append(np.zeros(50), np.ones(len(t1_mni_a_f_norm)))\n",
        "print(testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R60kwlpOwo0",
        "outputId": "4b753b7c-f13e-4e3e-963a-119169dfc13d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(370, 80, 96, 80, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "t1_mni_a_f_norm = np.append(t1_mni_a_norm[:50], t1_mni_a_f_norm, axis = 0 )\n",
        "t1_mni_a_f_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ-SJnUGPZ8p"
      },
      "outputs": [],
      "source": [
        "losses_test = [] \n",
        "p = tf.keras.losses.MeanSquaredError()\n",
        "for i in range(np.shape(t1_abide)[0]):\n",
        "  predicted_test = autoencoder.predict(t1_abide[i:i+1])\n",
        "  losses_test.append(p(predicted_test, t1_abide[i:i+1]).numpy())\n",
        "print(losses_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "dKTDSRVMPZ8u",
        "outputId": "03afafe2-64ad-49fa-f436-af5b70b40002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC:  0.9941249999999999\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold_at_max_diff =  0.012769941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nval_pred_labels = mses > threshold\\nprint(val_pred_labels, mses)\\n# to get max of predictions\\n    \\nreport = classification_report(labels, val_pred_labels)\\np_score = precision_score(labels, val_pred_labels)\\nr_score = recall_score(labels, val_pred_labels)\\nf1 = f1_score(labels, val_pred_labels)\\nmatthews = matthews_corrcoef(labels, val_pred_labels)\\nbalanced_accuracy = balanced_accuracy_score(labels, val_pred_labels)\\nconfusion_matrix = sklearn.metrics.confusion_matrix(labels, val_pred_labels)\\nTN = confusion_matrix[0][0]\\nFP = confusion_matrix[0][1]\\nFN = confusion_matrix[1][0]\\nTP = confusion_matrix[1][1]\\nspecificity = TN/(TN+FP)\\naccuracy = sklearn.metrics.accuracy_score(labels, val_pred_labels)\\n\\nprint(report)\\nprint(\"precision_score: \", p_score)\\nprint(\"th : \", threshold)\\nprint(\"recall/sensitivity \", r_score)\\nprint(\"f1_score \", f1)\\nprint(\"matthews_corrcoef \", matthews)\\nprint(\"balanced_accuracy_score \", balanced_accuracy)\\nprint(\"confusion_matrix \\n\", confusion_matrix)\\nprint(\"specificity \", specificity)\\nprint(\"Accuracy \", accuracy)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "labels = testing_labels\n",
        "mses = losses_test\n",
        "\n",
        "y_true = labels\n",
        "y_score = mses\n",
        "\n",
        "# Compute fpr, tpr, thresholds and roc auc\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(\"AUC: \", roc_auc)\n",
        "\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(\"ROC on Validation dataset \")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "diff = np.abs(np.array(fpr) - np.array(tpr))\n",
        "max_diff = np.max(diff)\n",
        "index_of_max_diff = np.argmax(diff)\n",
        "threshold_at_max_diff =  thresholds[index_of_max_diff]\n",
        "print(\"threshold_at_max_diff = \", threshold_at_max_diff)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6F4ls35Pj1e",
        "outputId": "ef773c92-8b15-4f69-9986-3e71d9f5cf3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix \n",
            " [[ 48   2]\n",
            " [  2 318]]\n",
            "accuracy in identifying the correct alignments: 98.91891891891892 percent\n"
          ]
        }
      ],
      "source": [
        "wrong_predicts = 0\n",
        "labels = []\n",
        "for loss in losses_test:\n",
        "  if loss >= threshold_at_max_diff:\n",
        "    labels = labels + [1]\n",
        "  else:\n",
        "    labels = labels + [0]\n",
        "accuracy = accuracy_score(testing_labels, labels)\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(testing_labels, labels)\n",
        "TN = confusion_matrix[0][0]\n",
        "FP = confusion_matrix[0][1]\n",
        "FN = confusion_matrix[1][0]\n",
        "TP = confusion_matrix[1][1]\n",
        "print(\"confusion_matrix \\n\", confusion_matrix)\n",
        "print(f'accuracy in identifying the correct alignments: {accuracy*100} percent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFGkSyMKXhl_",
        "outputId": "ceccb5b0-76b7-4756-d49f-209ee760cd65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 80, 96, 80, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "t1_abide = t1_mni_a_norm[50:]\n",
        "t1_abide.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJsbYa-SXhmF"
      },
      "outputs": [],
      "source": [
        "losses_test = [] \n",
        "for i in range(np.shape(t1_abide)[0]):\n",
        "  predicted_test = autoencoder.predict(t1_abide[i:i+1])\n",
        "  losses_test.append(p(predicted_test, t1_abide[i:i+1]).numpy())\n",
        "print(losses_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nplH82AJIQvu"
      },
      "outputs": [],
      "source": [
        "testing_labels_t = np.zeros(len(t1_abide))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCjLZj-tXhmJ",
        "outputId": "b1c2c5d8-670d-4178-c113-8681400ea7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_matrix \n",
            " [[13  1]\n",
            " [ 0  0]]\n",
            "accuracy in identifying the correct alignments: 92.85714285714286 percent\n"
          ]
        }
      ],
      "source": [
        "wrong_predicts = 0\n",
        "labels = []\n",
        "for loss in losses_test:\n",
        "  if loss >= threshold_at_max_diff:\n",
        "    labels = labels + [1]\n",
        "  else:\n",
        "    labels = labels + [0]\n",
        "accuracy = accuracy_score(testing_labels_t, labels)\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(testing_labels_t, labels)\n",
        "print(\"confusion_matrix \\n\", confusion_matrix)\n",
        "print(f'accuracy in identifying the correct alignments: {accuracy*100} percent')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}